# tiny_gpt_cpu
TinyGPT that trains a ~42â€¯Mâ€‘parameter language model on a small custom corpus of western church philosophers from Gutenberg: Augustine and Saint Thomas Aquinas

## Quick start

```bash
# clone the repo (or unzip the archive you downloaded)
cd tiny_gpt_cpu
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt
```

1. Place your cleaned corpus at `corpus/corpus_clean.txt`.
   *Use `clean_corpus.py` if youâ€™re using Project Gutenberg sources.*

2. Train:

```bash
python train.py
```

3. Generate text from the trained checkpoint:

```bash
python generate.py --prompt "Who is the son of God?"
```

Example Results:

```bash
Starting TinyGPT Text Generation...
ğŸ“– Prompt: 'Who is the son of God'
ğŸ¯ Target tokens: 100
ğŸŒ¡ï¸  Temperature: 0.7
ğŸ”§ Loading model and tokenizer...
   Vocabulary size: 50,257
ğŸ“‚ Loading checkpoint: checkpoint_epoch5.pt
âœ… Model loaded and ready for generation

============================================================
ğŸ­ Starting generation...
   Initial prompt tokens: 6
   Generated 10/100 tokens...
   Generated 20/100 tokens...
   Generated 30/100 tokens...
   Generated 40/100 tokens...
   Generated 50/100 tokens...
   Generated 60/100 tokens...
   Generated 70/100 tokens...
   Generated 80/100 tokens...
   Generated 90/100 tokens...
âœ… Generation complete! Total tokens: 106
============================================================
ğŸ‰ GENERATED TEXT:
============================================================
Who is the son of God, and whom God has given. For
he says, "Hine own son shall send forth Thy law;" and
in which seditions, "Preareth shall offer up," and what
dantec to the judgment of choice, and to "His
commandment." He adds, "The Lord hath rent up the people of God,"
otherwise than "His grace," and "His coming up the Lord Jesus,"
He adds, "And it shall not be greater than
============================================================
```


## Directory layout
```
tiny_gpt_cpu/
â”œâ”€â”€ train.py              # main training entryâ€‘point
â”œâ”€â”€ generate.py           # sampling helper
â”œâ”€â”€ model.py              # TinyGPT architecture
â”œâ”€â”€ requirements.txt
â””â”€â”€ corpus/
    â”œâ”€â”€ clean_corpus.py   # Clean downloaded gutenberg files in pg[number].txt format
    â””â”€â”€ corpus_clean.txt  # Cleaned corpus of text
```

## Requirements
* Python â‰¥3.9
* PyTorch â‰¥2.2.1 (CPU build is fine)
* numpy, tiktoken
